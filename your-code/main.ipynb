{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 -  Explore the Internal Dataset\n",
    "\n",
    "In this lab, we will start off by working with the wine dataset in scikit-learn. We will select the wine dataset and use a clustering algorithm to learn more about the functionalities of this library. \n",
    "\n",
    "We start off by loading the dataset using the `load_wine` function ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)). In the cell below, we will import the function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the `load_wine` function and assign the wine dataset to a variable called `wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "wine=load_wine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, list the keys of the variable `wine` to examine its contents. Note that the `load_wine` function does not return dataframes. It returns you a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, list the feature names. These are the different characteristics of the wine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the description of the dataset in the cell below using the `DESCR` attribute of the `wine` variable.\n",
    "\n",
    "*Hint: If your output is ill-formatted by displaying linebreaks as `\\n`, it means you are not using the print function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(wine['DESCR'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the description, we see that all columns are numeric. We also know that there is no missing data \n",
    "\n",
    "Let's plot the alcohol content histogram. Recall that we are working with a numpy array and will need to use a matplotlib function to produce a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.23, 13.2 , 13.16, 14.37, 13.24, 14.2 , 14.39, 14.06, 14.83,\n",
       "       13.86, 14.1 , 14.12, 13.75, 14.75, 14.38, 13.63, 14.3 , 13.83,\n",
       "       14.19, 13.64, 14.06, 12.93, 13.71, 12.85, 13.5 , 13.05, 13.39,\n",
       "       13.3 , 13.87, 14.02, 13.73, 13.58, 13.68, 13.76, 13.51, 13.48,\n",
       "       13.28, 13.05, 13.07, 14.22, 13.56, 13.41, 13.88, 13.24, 13.05,\n",
       "       14.21, 14.38, 13.9 , 14.1 , 13.94, 13.05, 13.83, 13.82, 13.77,\n",
       "       13.74, 13.56, 14.22, 13.29, 13.72, 12.37, 12.33, 12.64, 13.67,\n",
       "       12.37, 12.17, 12.37, 13.11, 12.37, 13.34, 12.21, 12.29, 13.86,\n",
       "       13.49, 12.99, 11.96, 11.66, 13.03, 11.84, 12.33, 12.7 , 12.  ,\n",
       "       12.72, 12.08, 13.05, 11.84, 12.67, 12.16, 11.65, 11.64, 12.08,\n",
       "       12.08, 12.  , 12.69, 12.29, 11.62, 12.47, 11.81, 12.29, 12.37,\n",
       "       12.29, 12.08, 12.6 , 12.34, 11.82, 12.51, 12.42, 12.25, 12.72,\n",
       "       12.22, 11.61, 11.46, 12.52, 11.76, 11.41, 12.08, 11.03, 11.82,\n",
       "       12.42, 12.77, 12.  , 11.45, 11.56, 12.42, 13.05, 11.87, 12.07,\n",
       "       12.43, 11.79, 12.37, 12.04, 12.86, 12.88, 12.81, 12.7 , 12.51,\n",
       "       12.6 , 12.25, 12.53, 13.49, 12.84, 12.93, 13.36, 13.52, 13.62,\n",
       "       12.25, 13.16, 13.88, 12.87, 13.32, 13.08, 13.5 , 12.79, 13.11,\n",
       "       13.23, 12.58, 13.17, 13.84, 12.45, 14.34, 13.48, 12.36, 13.69,\n",
       "       12.85, 12.96, 13.78, 13.73, 13.45, 12.82, 13.58, 13.4 , 12.2 ,\n",
       "       12.77, 14.16, 13.71, 13.4 , 13.27, 13.17, 14.13])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['data'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., 10., 19., 31., 21., 27., 25., 25., 17.,  2.]),\n",
       " array([11.03, 11.41, 11.79, 12.17, 12.55, 12.93, 13.31, 13.69, 14.07,\n",
       "        14.45, 14.83]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANqElEQVR4nO3df6jd9X3H8edrxrLNOqrk6lJrdjuRUhk0ysUVBOnmWlId/mAIk9IFJtz+oayFli1U2BxjENmsfw1LRGkY1iFY0U23KqFFCp3bjURNiJ2upK2aJde5oWXQLfreH/frdon3eM49P+735uPzAZdzvp/z/eb78uPJK998z/d8k6pCktSun+s7gCRptix6SWqcRS9JjbPoJalxFr0kNW7LRu5s69atNT8/v5G7lKTT3oEDB16rqrlxt9/Qop+fn2dpaWkjdylJp70kP5pke0/dSFLjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4zb0m7E6Pczvfqy3fR/dc01v+5Za5RG9JDXOopekxg0t+iQ/n+Sfkjyb5HCSP+3Gz03yZJIXu8dzZh9XkrReoxzR/wz4zar6BLAD2Jnkk8BuYH9VXQzs75YlSZvM0KKvFT/tFs/sfgq4DtjXje8Drp9JQknSREY6R5/kjCQHgRPAk1X1NHB+VR0D6B7PG7DtYpKlJEvLy8vTyi1JGtFIRV9Vb1XVDuAjwOVJfm3UHVTV3qpaqKqFubmx/4EUSdKY1nXVTVX9J/BdYCdwPMk2gO7xxNTTSZImNspVN3NJPtQ9/wXgt4AXgEeBXd1qu4BHZhVSkjS+Ub4Zuw3Yl+QMVv5geLCq/i7J94EHk9wM/Bi4cYY5JUljGlr0VfUccOka4/8OXDWLUJKk6fGbsZLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcaPcj15q3vzux3rb99E91/S2b70/eEQvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXFDiz7JhUm+k+RIksNJvtiN357klSQHu5+rZx9XkrReo9zr5iTw5ap6JsnZwIEkT3av3VVVfzm7eJKkSQ0t+qo6Bhzrnr+Z5AhwwayDSZKmY113r0wyD1wKPA1cAdya5PeAJVaO+v9jjW0WgUWA7du3TxhXak+fd87si3fs3Fgjfxib5IPAQ8CXquoN4G7gImAHK0f8d661XVXtraqFqlqYm5ubQmRJ0nqMVPRJzmSl5O+vqm8BVNXxqnqrqt4G7gEun11MSdK4RrnqJsC9wJGq+tqq8W2rVrsBODT9eJKkSY1yjv4K4PPA80kOdmNfBW5KsgMo4CjwhZkklCRNZJSrbr4HZI2XHp9+HEnStPnNWElqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGbek7gLTa/O7H+o4gNccjeklqnEUvSY0bWvRJLkzynSRHkhxO8sVu/NwkTyZ5sXs8Z/ZxJUnrNcoR/Ungy1X1ceCTwC1JLgF2A/ur6mJgf7csSdpkhhZ9VR2rqme6528CR4ALgOuAfd1q+4DrZxVSkjS+dZ2jTzIPXAo8DZxfVcdg5Q8D4LwB2ywmWUqytLy8PFlaSdK6jVz0ST4IPAR8qareGHW7qtpbVQtVtTA3NzdORknSBEYq+iRnslLy91fVt7rh40m2da9vA07MJqIkaRKjXHUT4F7gSFV9bdVLjwK7uue7gEemH0+SNKlRvhl7BfB54PkkB7uxrwJ7gAeT3Az8GLhxNhElSZMYWvRV9T0gA16+arpxJEnT5jdjJalx3tRsE/MGX5KmwSN6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOm5pJ2nB93bDv6J5retlv3zyil6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxg0t+iT3JTmR5NCqsduTvJLkYPdz9WxjSpLGNcoR/TeAnWuM31VVO7qfx6cbS5I0LUOLvqqeAl7fgCySpBmY5Bz9rUme607tnDO1RJKkqRq36O8GLgJ2AMeAOwetmGQxyVKSpeXl5TF3J0ka11hFX1XHq+qtqnobuAe4/D3W3VtVC1W1MDc3N25OSdKYxir6JNtWLd4AHBq0riSpX0P/4ZEkDwCfArYmeRn4E+BTSXYABRwFvjDDjJKkCQwt+qq6aY3he2eQRZI0A34zVpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaN7Tok9yX5ESSQ6vGzk3yZJIXu8dzZhtTkjSuUY7ovwHsPGVsN7C/qi4G9nfLkqRNaGjRV9VTwOunDF8H7Oue7wOun3IuSdKUbBlzu/Or6hhAVR1Lct6gFZMsAosA27dvH3N3/Zrf/VjfESRpbDP/MLaq9lbVQlUtzM3NzXp3kqRTjFv0x5NsA+geT0wvkiRpmsYt+keBXd3zXcAj04kjSZq2US6vfAD4PvCxJC8nuRnYA3w6yYvAp7tlSdImNPTD2Kq6acBLV005iyRpBvxmrCQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXFbJtk4yVHgTeAt4GRVLUwjlCRpeiYq+s5vVNVrU/h1JEkz4KkbSWrcpEVfwBNJDiRZXGuFJItJlpIsLS8vT7g7SdJ6TVr0V1TVZcBngVuSXHnqClW1t6oWqmphbm5uwt1JktZroqKvqle7xxPAw8Dl0wglSZqesYs+yVlJzn7nOfAZ4NC0gkmSpmOSq27OBx5O8s6v882q+oeppJIkTc3YRV9VPwQ+McUskqQZ8PJKSWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktS4Se5HL0mnlfndj/W276N7rult3x7RS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMadNpdX9nlZlCSdzjyil6TGWfSS1DiLXpIaN1HRJ9mZ5AdJXkqye1qhJEnTM3bRJzkD+Cvgs8AlwE1JLplWMEnSdExyRH858FJV/bCq/hv4G+C66cSSJE3LJJdXXgD8ZNXyy8Cvn7pSkkVgsVv8aZIfrHM/W4HXxkq4Mcw3GfNNxnyT2bB8uWOszd7J9yuT7HuSos8aY/Wugaq9wN6xd5IsVdXCuNvPmvkmY77JmG8y75d8k5y6eRm4cNXyR4BXJ4sjSZq2SYr+n4GLk3w0yQeA3wUenU4sSdK0jH3qpqpOJrkV+DZwBnBfVR2eWrL/N/Zpnw1ivsmYbzLmm8z7Il+q3nVaXZLUEL8ZK0mNs+glqXG9FX2S+5KcSHJo1diNSQ4neTvJwEuKNuLWCxPmO5rk+SQHkyxtYL6/SPJCkueSPJzkQwO27Wv+Rs3X1/z9WZftYJInknx4wLZ9zd+o+XqZv1WvfSVJJdk6YNte5m8d+fp6/92e5JVuvweTXD1g2/XPX1X18gNcCVwGHFo19nHgY8B3gYUB250B/Cvwq8AHgGeBSzZLvm69o8DWHubvM8CW7vkdwB2bbP6G5ut5/n5p1fM/AL6+yeZvaL4+568bv5CVCzR+tFaGPudvlHw9v/9uB74yZLux5q+3I/qqegp4/ZSxI1U17JuzG3LrhQnybYgB+Z6oqpPd4j+y8t2GU/U5f6Pk2xAD8r2xavEs1vgCIP3O3yj5NsRa+Tp3AX/I4Gy9zd+I+TbEe+QbZqz5Ox3P0a9164ULesoySAFPJDnQ3QKiD78P/P0a45tl/gblgx7nL8mfJ/kJ8Dngj9dYpdf5GyEf9DR/Sa4FXqmqZ99jtd7mb8R80O/v31u703P3JTlnjdfHmr/TsehHuvVCz66oqstYubPnLUmu3MidJ7kNOAncv9bLa4xt6PwNyQc9zl9V3VZVF3bZbl1jlV7nb4R80MP8JflF4DYG/+Hzf6uuMTbz+VtHPujv/Xc3cBGwAzgG3LnGOmPN3+lY9Jv+1gtV9Wr3eAJ4mJW/bm2IJLuA3wY+V91JvVP0On8j5Ot1/lb5JvA7a4xvlvffoHx9zd9FwEeBZ5McZWVenknyy6es19f8jZqvt/dfVR2vqreq6m3gngH7HWv+Tsei39S3XkhyVpKz33nOygeQ7/rkf0b73gn8EXBtVf3XgNV6m79R8vU8fxevWrwWeGGN1fqcv6H5+pq/qnq+qs6rqvmqmmelkC6rqn87ZdVe5m/UfD2//7atWrxhwH7Hm79ZfrI85NPjB1j568n/sDLpN3f/cS8DPwOOA9/u1v0w8Piqba8G/oWVT59v20z5WPk0/Nnu5/AG53uJlfN3B7ufr2+y+Ruar+f5e4iV31zPAX8LXLDJ5m9ovj7n75TXj9JdubJZ5m+UfD2///4aeL77//sosG1a8+ctECSpcafjqRtJ0jpY9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalx/wu0rXFzp0yIIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here:\n",
    "plt.hist(wine['data'][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Clustering the Internal Dataset\n",
    "\n",
    "In this portion of the lab, we will cluster the data to find common traits between the different wines. We will use the k-means clustering algorithm to achieve this goal.\n",
    "\n",
    "#### We start by importing k-means from scikit-learn and then proceed to create 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4, random_state=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "kmeans=KMeans(n_clusters=4, random_state=0)\n",
    "\n",
    "kmeans.fit(wine['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 3, 1, 3, 1, 3, 3, 1,\n",
       "       3, 3, 1, 1, 2, 3, 3, 2, 2, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 1,\n",
       "       1, 1, 3, 3, 3, 3, 3, 2, 1, 3, 1, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 1,\n",
       "       1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3,\n",
       "       1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 2, 3, 1, 1, 1, 3, 3, 3, 1,\n",
       "       1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2,\n",
       "       2, 1], dtype=int32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "kmeans_labels=kmeans.fit(wine['data']).labels_\n",
    "kmeans_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the size of each cluster. This can be done by counting the number of occurrences of each unique label in the list above.\n",
    "\n",
    "Which is the largest cluster of the 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    59\n",
       "3    57\n",
       "2    39\n",
       "0    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "pd.Series(kmeans_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest is 1\n"
     ]
    }
   ],
   "source": [
    "# Your answer here:\n",
    "pd.Series(kmeans_labels).value_counts().max()\n",
    "\n",
    "print('The highest is 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the shape of `wine['data']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the first 5 records in `wine['data']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n",
       "        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, 1.860e+01, 1.010e+02, 2.800e+00,\n",
       "        3.240e+00, 3.000e-01, 2.810e+00, 5.680e+00, 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n",
       "        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n",
       "        1.480e+03],\n",
       "       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n",
       "        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n",
       "        7.350e+02]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine['data'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know the data object is a 2-dimensional array in which there are 178 rows and 13 columns. Each row is a data record and each column is a feature.\n",
    "\n",
    "#### What is the average ash content for each cluster? \n",
    "\n",
    "*Hints:* \n",
    "\n",
    "* *Ash* is the 3rd column.\n",
    "\n",
    "* The data object is not a Pandas dataframe so you can't apply `pandas.DataFrame.groupby`. Instead, you can use `np.average`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df=pd.DataFrame(wine['data'],columns=wine['feature_names'])\n",
    "df['kmeans_labels']=kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.506957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.379322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.390769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ash\n",
       "kmeans_labels          \n",
       "0              2.506957\n",
       "1              2.379322\n",
       "2              2.390769\n",
       "3              2.280000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kmeans_labels').agg({'ash':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Load and Explore an External Dataset\n",
    "\n",
    "We will now load an external dataset using Pandas and use scikit learn to explore the data. In this portion of the lab, we will use a [patient dataset from Kaggle](https://www.kaggle.com/miles99/patient-admission-dataset-for-learning-data-mining). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv('../patient-admission-dataset-for-learning-data-mining.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, print the first five rows of the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>patient_email</th>\n",
       "      <th>doctor_phone</th>\n",
       "      <th>patient_gender</th>\n",
       "      <th>patient_dob</th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>patient_nhs_number</th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>appointment_date</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>prescribed_medicines</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Celestyna Dillimore</td>\n",
       "      <td>cdillimore0@dion.ne.jp</td>\n",
       "      <td>674-914-1212</td>\n",
       "      <td>Female</td>\n",
       "      <td>10/18/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>59</td>\n",
       "      <td>176</td>\n",
       "      <td>8.200152e+09</td>\n",
       "      <td>Sarena Waliszek</td>\n",
       "      <td>5/1/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>triamcinolone acetonide</td>\n",
       "      <td>I669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Meta Michieli</td>\n",
       "      <td>mmichieli1@loc.gov</td>\n",
       "      <td>172-580-3586</td>\n",
       "      <td>Female</td>\n",
       "      <td>2/8/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farris Robinet</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cordie Sancto</td>\n",
       "      <td>csancto2@cafepress.com</td>\n",
       "      <td>794-222-5085</td>\n",
       "      <td>Female</td>\n",
       "      <td>10/9/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>6.145594e+09</td>\n",
       "      <td>Kaspar Spitaro</td>\n",
       "      <td>10/5/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Josh De Ambrosis</td>\n",
       "      <td>jde3@amazon.co.jp</td>\n",
       "      <td>856-540-5195</td>\n",
       "      <td>Male</td>\n",
       "      <td>9/10/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rafferty Fowls</td>\n",
       "      <td>10/21/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Delinda Alfonsini</td>\n",
       "      <td>dalfonsini4@opensource.org</td>\n",
       "      <td>938-978-1131</td>\n",
       "      <td>Female</td>\n",
       "      <td>2/26/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "      <td>140</td>\n",
       "      <td>4.804758e+08</td>\n",
       "      <td>Glenna MacNeachtain</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         patient_name               patient_email  doctor_phone  \\\n",
       "0   1  Celestyna Dillimore      cdillimore0@dion.ne.jp  674-914-1212   \n",
       "1   2        Meta Michieli          mmichieli1@loc.gov  172-580-3586   \n",
       "2   3        Cordie Sancto      csancto2@cafepress.com  794-222-5085   \n",
       "3   4     Josh De Ambrosis           jde3@amazon.co.jp  856-540-5195   \n",
       "4   5    Delinda Alfonsini  dalfonsini4@opensource.org  938-978-1131   \n",
       "\n",
       "  patient_gender patient_dob  patient_diabetic  patient_allergic  \\\n",
       "0         Female  10/18/2018             False              True   \n",
       "1         Female    2/8/2018             False              True   \n",
       "2         Female   10/9/2018              True              True   \n",
       "3           Male   9/10/2018              True              True   \n",
       "4         Female   2/26/2018             False              True   \n",
       "\n",
       "   patient_weight_kg  patient_height_sm  patient_nhs_number  \\\n",
       "0                 59                176        8.200152e+09   \n",
       "1                 77                186                 NaN   \n",
       "2                 90                177        6.145594e+09   \n",
       "3                 70                150                 NaN   \n",
       "4                 82                140        4.804758e+08   \n",
       "\n",
       "           doctor_name appointment_date  patient_show  is_regular_visit  \\\n",
       "0      Sarena Waliszek         5/1/2018          True              True   \n",
       "1       Farris Robinet        12/7/2017          True              True   \n",
       "2       Kaspar Spitaro        10/5/2018         False             False   \n",
       "3       Rafferty Fowls       10/21/2018         False              True   \n",
       "4  Glenna MacNeachtain       11/15/2018         False             False   \n",
       "\n",
       "      prescribed_medicines diagnosis  \n",
       "0  triamcinolone acetonide      I669  \n",
       "1                      NaN       NaN  \n",
       "2                      NaN       NaN  \n",
       "3                      NaN       NaN  \n",
       "4                      NaN       NaN  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print the column types and check which columns have been misclassified by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1000 non-null   int64  \n",
      " 1   patient_name          1000 non-null   object \n",
      " 2   patient_email         1000 non-null   object \n",
      " 3   doctor_phone          1000 non-null   object \n",
      " 4   patient_gender        1000 non-null   object \n",
      " 5   patient_dob           1000 non-null   object \n",
      " 6   patient_diabetic      1000 non-null   bool   \n",
      " 7   patient_allergic      1000 non-null   bool   \n",
      " 8   patient_weight_kg     1000 non-null   int64  \n",
      " 9   patient_height_sm     1000 non-null   int64  \n",
      " 10  patient_nhs_number    796 non-null    float64\n",
      " 11  doctor_name           942 non-null    object \n",
      " 12  appointment_date      1000 non-null   object \n",
      " 13  patient_show          1000 non-null   bool   \n",
      " 14  is_regular_visit      1000 non-null   bool   \n",
      " 15  prescribed_medicines  512 non-null    object \n",
      " 16  diagnosis             512 non-null    object \n",
      "dtypes: bool(4), float64(1), int64(3), object(9)\n",
      "memory usage: 105.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "patients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that none of the date columns have been correctly classified. Also, some columns contain qualitative data that can be dropped.\n",
    "\n",
    "First, transform the `patient_dob` and `appointment_date` columns to datetime using the `pd.to_datetime` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "patients['patient_dob'] =  pd.to_datetime(patients['patient_dob'], format='%m/%d/%Y')\n",
    "patients['appointment_date'] =  pd.to_datetime(patients['appointment_date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, drop the `id`, `patient_name`, `patient_email`, `patient_nhs_number`, and `doctor_phone` columns. These are not quantitative columns and will not contribute to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "columns_to_drop=['id', 'patient_name', 'patient_email', 'patient_nhs_number', 'doctor_phone']\n",
    "patients_clean=patients.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we work on the missing data. Most ML algorithms will not perform as intended if there are missing data.\n",
    "\n",
    "In the cell below, count how many rows contain missing data in each column. You should see three columns contain missing data:\n",
    "\n",
    "* `doctor_name`: 58 missing data\n",
    "* `prescribed_medicines`: 488 missing data\n",
    "* `diagnosis`: 488 missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_gender            0\n",
       "patient_dob               0\n",
       "patient_diabetic          0\n",
       "patient_allergic          0\n",
       "patient_weight_kg         0\n",
       "patient_height_sm         0\n",
       "doctor_name              58\n",
       "appointment_date          0\n",
       "patient_show              0\n",
       "is_regular_visit          0\n",
       "prescribed_medicines    488\n",
       "diagnosis               488\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "patients_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issues are found in the `prescribed_medicines` and `diagnosis` columns. Can we simply drop these rows?\n",
    "\n",
    "The answer is not yet. Because when there are missing data in these columns, it doesn't mean the data records are broken. Instead, it means no medication was prescribed and no diagnosis was recorded. Therefore, once we fill in the missing data these columns will be fine. But we'll revisit these columns and decide whether we will eventually drop them when we look at how many unique values are there in these categorical columns.  \n",
    "\n",
    "For the `prescribed_medicines` column, fill the missing values with the value `no prescription`. For the `diagnosis` column, fill the missing values with `no diagnosis`.\n",
    "\n",
    "*Hint: Use [`pandas.DataFrame.fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "patients_clean['prescribed_medicines'].fillna('no_prescrition',inplace=True)\n",
    "patients_clean['diagnosis'].fillna('no_diagnosis',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about `doctor_name`? Since a doctor visit without a doctor name might not be meaningful, we will drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "patients_clean.drop('doctor_name',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another step in preprocessing that can be performed by scikit-learn is label encoding. \n",
    "\n",
    "We have 4 columns that are of `bool` type. We would like to convert them to an integer column containing either zero or one. We can do this using [scikit-learn's label encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "In the cell below, import the label encoder and encode the 4 boolean columns (*patient_diabetic*, *patient_allergic*, *patient_show*, *is_regular_visit*) with `0` and `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "list_bool=['patient_diabetic', 'patient_allergic', 'patient_show', 'is_regular_visit']\n",
    "\n",
    "for column in list_bool:\n",
    "    le.fit(patients_clean[column])\n",
    "    patients_clean[column]=le.transform(patients_clean[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the data dtypes to confirm those four `bool` columns are converted to `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_gender                  object\n",
       "patient_dob             datetime64[ns]\n",
       "patient_diabetic                 int64\n",
       "patient_allergic                 int64\n",
       "patient_weight_kg                int64\n",
       "patient_height_sm                int64\n",
       "appointment_date        datetime64[ns]\n",
       "patient_show                     int64\n",
       "is_regular_visit                 int64\n",
       "prescribed_medicines            object\n",
       "diagnosis                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "patients_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last step is to handle the `object` data.\n",
    "\n",
    "There are 4 `object` columns now: `patient_gender`, `doctor_name`, `prescribed_medicines`, and `diagnosis`. The gender columns\n",
    "\n",
    "In the next cell, check the unique values of each of the `object` columns using `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Female    504\n",
      "Male      496\n",
      "Name: patient_gender, dtype: int64\n",
      "\n",
      "----------------------------------\n",
      "no_prescrition                           488\n",
      "ALCOHOL                                    8\n",
      "Ibuprofen                                  7\n",
      "Acetaminophen                              6\n",
      "Triclosan                                  5\n",
      "                                        ... \n",
      "Tetracycline Hydrochloride                 1\n",
      "Metoclopramide Hydrochloride               1\n",
      "diphenhydramine citrate and ibuprofen      1\n",
      "Aurum Lavender Rose                        1\n",
      "Titanium Dioxide                           1\n",
      "Name: prescribed_medicines, Length: 414, dtype: int64\n",
      "\n",
      "----------------------------------\n",
      "no_diagnosis    488\n",
      "T2169             2\n",
      "S42262A           1\n",
      "S83409            1\n",
      "H15012            1\n",
      "               ... \n",
      "G318              1\n",
      "I669              1\n",
      "S90549D           1\n",
      "W16021            1\n",
      "S82264J           1\n",
      "Name: diagnosis, Length: 512, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "list_col=['patient_gender', 'prescribed_medicines','diagnosis']\n",
    "for x in list_col:\n",
    "    print('----------------------------------')\n",
    "    print(patients_clean[x].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The number of unique values is large for all three columns except `patient_gender`. We will handle these columns differently.\n",
    "\n",
    "For `diagnosis`, there are too many unique values which will make ML difficult. However, we can re-encode the values to either with or without diagnosis. Remember at an earlier step we filled in the missing values of this column with *no diagnosis*? We can re-encode *no diagnosis* to `0` and all other values to `1`. In this way we can tremendously simply this column.\n",
    "\n",
    "For `prescribed_medicines`, we can drop this column because it is perfectly correlated with `diagnosis`. Whenever there is no diagnosis, there is no prescribed medicine. So we don't need to keep this duplicated data.\n",
    "\n",
    "How about `doctor_name`? There are not excessive unique values but still quite many (19). We may either drop or keep it but keeping it will make the analysis more complicated. So due to the length of this lab let's drop it.\n",
    "\n",
    "How about `gender`? This one is easy. Just like re-encoding the boolean values, we can re-encode gender to `0` and `1` because there are only 2 unique values.\n",
    "\n",
    "In the next cells, do the following:\n",
    "\n",
    "1. Create a new column called `diagnosis_int` that has `0` and `1` based on the values in `diagnosis`.\n",
    "\n",
    "1. Create a new column called `patient_gender_int` that has `0` and `1` based on the values in `patient_gender`.\n",
    "\n",
    "1. Drop the following columns: `doctor_name`, `diagnosis`, `prescribed_medicines`, and `patient_gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "patients_clean['patient_gender_int']=pd.Series(np.where(patients_clean.patient_gender.values == 'Male', 1, 0))\n",
    "patients_clean['diagnosis_int']=pd.Series(np.where(patients_clean.diagnosis.values == 'no_diagnosis', 0, 1))\n",
    "\n",
    "patients_clean.drop(list_col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the head again to ensure the re-encoding and dropping are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_dob</th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>appointment_date</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>patient_gender_int</th>\n",
       "      <th>diagnosis_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>176</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>186</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>140</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_dob  patient_diabetic  patient_allergic  patient_weight_kg  \\\n",
       "0  2018-10-18                 0                 1                 59   \n",
       "1  2018-02-08                 0                 1                 77   \n",
       "2  2018-10-09                 1                 1                 90   \n",
       "3  2018-09-10                 1                 1                 70   \n",
       "4  2018-02-26                 0                 1                 82   \n",
       "\n",
       "   patient_height_sm appointment_date  patient_show  is_regular_visit  \\\n",
       "0                176       2018-05-01             1                 1   \n",
       "1                186       2017-12-07             1                 1   \n",
       "2                177       2018-10-05             0                 0   \n",
       "3                150       2018-10-21             0                 1   \n",
       "4                140       2018-11-15             0                 0   \n",
       "\n",
       "   patient_gender_int  diagnosis_int  \n",
       "0                   0              1  \n",
       "1                   0              0  \n",
       "2                   0              0  \n",
       "3                   1              0  \n",
       "4                   0              0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "patients_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that all patients are no older than 2 years. However, their weights and heights indicate that they are adults. This cannot be true. Therefore, we can either trust the weight and height columns or the DOB column. Since there are other columns that indicate that these are adults (they have emails, some have diabetes) we will drop the `patient_dob` column. We will also drop the `appointment_date` column since it has too many unique values to transform to a dummy variable. Drop the two columns in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "patients_clean.drop('patient_dob',axis=1,inplace=True)\n",
    "patients_clean.drop('appointment_date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data is now ready for clustering. Let's use k-means again.\n",
    "\n",
    "We start by initializing and fitting a model in the cell below. Call this model patients_cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4, random_state=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=4, random_state=0)\n",
    "\n",
    "kmeans.fit(patients_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the labels to the dataframe. Do this by accessing the `labels_` in the `patients_cluster` model and assign them to a new column in `patients` that you will call `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "patients_clean['labels']=kmeans.fit(patients_clean).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>patient_gender_int</th>\n",
       "      <th>diagnosis_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.494208</td>\n",
       "      <td>0.517375</td>\n",
       "      <td>63.104247</td>\n",
       "      <td>176.988417</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.494208</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.490637</td>\n",
       "      <td>94.029963</td>\n",
       "      <td>178.925094</td>\n",
       "      <td>0.501873</td>\n",
       "      <td>0.531835</td>\n",
       "      <td>0.468165</td>\n",
       "      <td>0.509363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.497942</td>\n",
       "      <td>65.637860</td>\n",
       "      <td>152.193416</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.510288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562771</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>97.696970</td>\n",
       "      <td>153.766234</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_diabetic  patient_allergic  patient_weight_kg  \\\n",
       "labels                                                          \n",
       "0               0.494208          0.517375          63.104247   \n",
       "1               0.505618          0.490637          94.029963   \n",
       "2               0.506173          0.497942          65.637860   \n",
       "3               0.562771          0.515152          97.696970   \n",
       "\n",
       "        patient_height_sm  patient_show  is_regular_visit  patient_gender_int  \\\n",
       "labels                                                                          \n",
       "0              176.988417      0.463320          0.494208            0.463320   \n",
       "1              178.925094      0.501873          0.531835            0.468165   \n",
       "2              152.193416      0.514403          0.555556            0.547325   \n",
       "3              153.766234      0.493506          0.519481            0.510823   \n",
       "\n",
       "        diagnosis_int  \n",
       "labels                 \n",
       "0            0.459459  \n",
       "1            0.509363  \n",
       "2            0.510288  \n",
       "3            0.575758  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using a `groupby`, find the mean of every variable in `patients` and group by the `labels` column. This summary will allow us to see how the patients differ between the clusters. Your output should look similar to the image below.\n",
    "\n",
    "![groupby mean](../groupby-mean.png)\n",
    "\n",
    "Additionally, add a comment to describe which columns have the largest difference between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Visualize K-Means Clusters\n",
    "\n",
    "How did k-means cluster the data? You can obtain an intuitive view with a scatter plot. Generate a 2-d cluster plot below using `matplotlib`. You need to choose 2 of the features from your cleaned and transformed dataset, and use color to represent the cluster label generated from k-means.\n",
    "\n",
    "If the scatter plot does not make any sense to you, it means the features you chose to visualize are not the right ones. You should be able to see 4 clear clusters with different colors in your visualization that suggests how k-means had clustered your data.\n",
    "\n",
    "![Cluster Visualization](../clusters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can visualize the clusters in 3-D scatter plot. Give it a try below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
